{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Pyolite",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<center>\n    <a href=\"https://cognitiveclass.ai\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%204/images/IDSNlogo.png\" width=\"300\"> </a>\n</center>\n\n# From Modeling to Evaluation\n\nEstimated time needed: **20** minutes\n\n## Objectives\n\nAfter completing this lab you will be able to:\n\n-   Create Models\n-   Evaluate the models\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Table of Contents\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n\n1.  [Recap](#0)<br>\n2.  [Data Modeling](#2)<br>\n3.  [Model Evaluation](#4)<br>\n    </div>\n    <hr>\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Recap <a id=\"0\"></a>\n\nIn Lab **From Understanding to Preparation**, we explored the data and prepared it for modeling.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "The data was compiled by a researcher named Yong-Yeol Ahn, who scraped tens of thousands of food recipes (cuisines and ingredients) from three different websites, namely:\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%202/images/lab2_fig3_allrecipes.png\" width=\"500\">\n<div align=\"center\">\nwww.allrecipes.com\n</div>\n<br/><br/>\n<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%202/images/lab2_fig4_epicurious.png\" width=\"500\">\n<div align=\"center\">\nwww.epicurious.com\n</div>\n<br/><br/>\n<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%202/images/lab2_fig5_menupan.png\" width=\"500\">\n<div align=\"center\">\nwww.menupan.com\n</div>\n<br/><br/>\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "For more information on Yong-Yeol Ahn and his research, you can read his paper on [Flavor Network and the Principles of Food Pairing](http://yongyeol.com/papers/ahn-flavornet-2011.pdf?utm_email=Email&utm_source=Nurture&utm_content=000026UJ&utm_term=10006555&utm_campaign=PLACEHOLDER&utm_id=SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork-20083987).\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "<strong>Important note:</strong> Please note that you are not expected to know how to program in python. The following code is meant to illustrate the stage of data collection, so it is totally fine if you do not understand the individual lines of code. There will be a full course in this certificate on programming in python, <a href=\"http://cocl.us/PY0101EN_DS0103EN_LAB4_PYTHON_edX\">Python for Data Science</a>, which will teach you how to program in Python if you decide to complete this certificate.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Using this notebook:\n\nTo run any of the following cells of code, you can type **Shift + Enter** to excute the code in a cell.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Download the library and dependencies that we will need to run this lab.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd # import library to read data into dataframe\npd.set_option(\"display.max_columns\", None)\nimport numpy as np # import numpy library\nimport re # import library for regular expression\nimport random # library for random number generation",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "We already placed the data on an IBM server for your convenience, so let's download it from server and read it into a dataframe called **recipes**.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "# Uncomment if running locally, else download data using the following code cell\n# recipes = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%202/recipes.csv\")\n\n# print(\"Data read into dataframe!\") # takes about 30 seconds",
      "metadata": {
        "button": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "collapsed": false,
        "trusted": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import piplite\nawait piplite.install(['skillsnetwork'])\nimport skillsnetwork\n\n# Download to current directory with same filename\nawait skillsnetwork.download_dataset(\n    \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%202/recipes.csv\",\n    \"recipes.csv\")\n\nrecipes = pd.read_csv(\"recipes.csv\")\nprint(\"Data read into dataframe!\") # takes about 30 seconds",
      "metadata": {
        "trusted": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "ename": "<class 'ValueError'>",
          "evalue": "Requested 'urllib3<1.27,>=1.26.7', but urllib3==2.0.7 is already installed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpiplite\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m piplite\u001b[38;5;241m.\u001b[39minstall([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskillsnetwork\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mskillsnetwork\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Download to current directory with same filename\u001b[39;00m\n",
            "File \u001b[0;32m/lib/python3.10/asyncio/futures.py:284\u001b[0m, in \u001b[0;36mFuture.__await__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncio_future_blocking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mawait wasn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt used with future\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/lib/python3.10/asyncio/tasks.py:304\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
            "File \u001b[0;32m/lib/python3.10/asyncio/futures.py:201\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
            "File \u001b[0;32m/lib/python3.10/asyncio/tasks.py:234\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    232\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_must_cancel:\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
            "File \u001b[0;32m/lib/python3.10/site-packages/piplite/piplite.py:80\u001b[0m, in \u001b[0;36m_PackageManager.install\u001b[0;34m(self, requirements, ctx, keep_going)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minstall\u001b[39m(\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m, requirements: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]], ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keep_going: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     78\u001b[0m ):\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m patch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicropip._micropip._get_pypi_json\u001b[39m\u001b[38;5;124m\"\u001b[39m, _get_pypi_json):\n\u001b[0;32m---> 80\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _MP_PACKAGE_MANAGER\u001b[38;5;241m.\u001b[39minstall(requirements, ctx, keep_going)\n",
            "File \u001b[0;32m/lib/python3.10/site-packages/micropip/_micropip.py:183\u001b[0m, in \u001b[0;36m_PackageManager.install\u001b[0;34m(self, requirements, ctx, keep_going)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m install_func\n\u001b[1;32m    181\u001b[0m     done_callback()\n\u001b[0;32m--> 183\u001b[0m transaction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_requirements(requirements, ctx, keep_going)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transaction[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    186\u001b[0m     failed_requirements \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    187\u001b[0m         [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreq\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m req \u001b[38;5;129;01min\u001b[39;00m transaction[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m    188\u001b[0m     )\n",
            "File \u001b[0;32m/lib/python3.10/site-packages/micropip/_micropip.py:173\u001b[0m, in \u001b[0;36m_PackageManager.gather_requirements\u001b[0;34m(self, requirements, ctx, keep_going)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m requirement \u001b[38;5;129;01min\u001b[39;00m requirements:\n\u001b[1;32m    169\u001b[0m     requirement_promises\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_requirement(requirement, ctx, transaction)\n\u001b[1;32m    171\u001b[0m     )\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m gather(\u001b[38;5;241m*\u001b[39mrequirement_promises)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transaction\n",
            "File \u001b[0;32m/lib/python3.10/asyncio/futures.py:284\u001b[0m, in \u001b[0;36mFuture.__await__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncio_future_blocking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mawait wasn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt used with future\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/lib/python3.10/asyncio/tasks.py:304\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
            "File \u001b[0;32m/lib/python3.10/asyncio/futures.py:201\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
            "File \u001b[0;32m/lib/python3.10/asyncio/tasks.py:232\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
            "File \u001b[0;32m/lib/python3.10/site-packages/micropip/_micropip.py:291\u001b[0m, in \u001b[0;36m_PackageManager.add_requirement\u001b[0;34m(self, requirement, ctx, transaction)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    287\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a pure Python 3 wheel for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreq\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can use `micropip.install(..., keep_going=True)` to get a list of all packages with missing wheels.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    289\u001b[0m         )\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_wheel(\n\u001b[1;32m    292\u001b[0m         req\u001b[38;5;241m.\u001b[39mname, maybe_wheel, maybe_ver, req\u001b[38;5;241m.\u001b[39mextras, ctx, transaction\n\u001b[1;32m    293\u001b[0m     )\n",
            "File \u001b[0;32m/lib/python3.10/site-packages/micropip/_micropip.py:316\u001b[0m, in \u001b[0;36m_PackageManager.add_wheel\u001b[0;34m(self, name, wheel, version, extras, ctx, transaction)\u001b[0m\n\u001b[1;32m    314\u001b[0m     dist \u001b[38;5;241m=\u001b[39m pkg_resources_distribution_for_wheel(zip_file, name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m???\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m recurs_req \u001b[38;5;129;01min\u001b[39;00m dist\u001b[38;5;241m.\u001b[39mrequires(extras):\n\u001b[0;32m--> 316\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_requirement(recurs_req, ctx, transaction)\n\u001b[1;32m    318\u001b[0m transaction[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwheels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend((name, wheel, version))\n",
            "File \u001b[0;32m/lib/python3.10/site-packages/micropip/_micropip.py:291\u001b[0m, in \u001b[0;36m_PackageManager.add_requirement\u001b[0;34m(self, requirement, ctx, transaction)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    287\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a pure Python 3 wheel for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreq\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can use `micropip.install(..., keep_going=True)` to get a list of all packages with missing wheels.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    289\u001b[0m         )\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_wheel(\n\u001b[1;32m    292\u001b[0m         req\u001b[38;5;241m.\u001b[39mname, maybe_wheel, maybe_ver, req\u001b[38;5;241m.\u001b[39mextras, ctx, transaction\n\u001b[1;32m    293\u001b[0m     )\n",
            "File \u001b[0;32m/lib/python3.10/site-packages/micropip/_micropip.py:316\u001b[0m, in \u001b[0;36m_PackageManager.add_wheel\u001b[0;34m(self, name, wheel, version, extras, ctx, transaction)\u001b[0m\n\u001b[1;32m    314\u001b[0m     dist \u001b[38;5;241m=\u001b[39m pkg_resources_distribution_for_wheel(zip_file, name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m???\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m recurs_req \u001b[38;5;129;01min\u001b[39;00m dist\u001b[38;5;241m.\u001b[39mrequires(extras):\n\u001b[0;32m--> 316\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_requirement(recurs_req, ctx, transaction)\n\u001b[1;32m    318\u001b[0m transaction[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwheels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend((name, wheel, version))\n",
            "    \u001b[0;31m[... skipping similar frames: _PackageManager.add_requirement at line 291 (1 times), _PackageManager.add_wheel at line 316 (1 times)]\u001b[0m\n",
            "File \u001b[0;32m/lib/python3.10/site-packages/micropip/_micropip.py:291\u001b[0m, in \u001b[0;36m_PackageManager.add_requirement\u001b[0;34m(self, requirement, ctx, transaction)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    287\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a pure Python 3 wheel for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreq\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can use `micropip.install(..., keep_going=True)` to get a list of all packages with missing wheels.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    289\u001b[0m         )\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_wheel(\n\u001b[1;32m    292\u001b[0m         req\u001b[38;5;241m.\u001b[39mname, maybe_wheel, maybe_ver, req\u001b[38;5;241m.\u001b[39mextras, ctx, transaction\n\u001b[1;32m    293\u001b[0m     )\n",
            "File \u001b[0;32m/lib/python3.10/site-packages/micropip/_micropip.py:316\u001b[0m, in \u001b[0;36m_PackageManager.add_wheel\u001b[0;34m(self, name, wheel, version, extras, ctx, transaction)\u001b[0m\n\u001b[1;32m    314\u001b[0m     dist \u001b[38;5;241m=\u001b[39m pkg_resources_distribution_for_wheel(zip_file, name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m???\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m recurs_req \u001b[38;5;129;01min\u001b[39;00m dist\u001b[38;5;241m.\u001b[39mrequires(extras):\n\u001b[0;32m--> 316\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_requirement(recurs_req, ctx, transaction)\n\u001b[1;32m    318\u001b[0m transaction[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwheels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend((name, wheel, version))\n",
            "File \u001b[0;32m/lib/python3.10/site-packages/micropip/_micropip.py:276\u001b[0m, in \u001b[0;36m_PackageManager.add_requirement\u001b[0;34m(self, requirement, ctx, transaction)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequirement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreq\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m==\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is already installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         )\n\u001b[1;32m    280\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m _get_pypi_json(req\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    281\u001b[0m maybe_wheel, maybe_ver \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_wheel(metadata, req)\n",
            "\u001b[0;31mValueError\u001b[0m: Requested 'urllib3<1.27,>=1.26.7', but urllib3==2.0.7 is already installed"
          ],
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "We will repeat the preprocessing steps that we implemented in Lab **From Understanding to Preparation** in order to prepare the data for modeling. For more details on preparing the data, please refer to Lab **From Understanding to Preparation**.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "# fix name of the column displaying the cuisine\ncolumn_names = recipes.columns.values\ncolumn_names[0] = \"cuisine\"\nrecipes.columns = column_names\n\n# convert cuisine names to lower case\nrecipes[\"cuisine\"] = recipes[\"cuisine\"].str.lower()\n\n# make the cuisine names consistent\nrecipes.loc[recipes[\"cuisine\"] == \"austria\", \"cuisine\"] = \"austrian\"\nrecipes.loc[recipes[\"cuisine\"] == \"belgium\", \"cuisine\"] = \"belgian\"\nrecipes.loc[recipes[\"cuisine\"] == \"china\", \"cuisine\"] = \"chinese\"\nrecipes.loc[recipes[\"cuisine\"] == \"canada\", \"cuisine\"] = \"canadian\"\nrecipes.loc[recipes[\"cuisine\"] == \"netherlands\", \"cuisine\"] = \"dutch\"\nrecipes.loc[recipes[\"cuisine\"] == \"france\", \"cuisine\"] = \"french\"\nrecipes.loc[recipes[\"cuisine\"] == \"germany\", \"cuisine\"] = \"german\"\nrecipes.loc[recipes[\"cuisine\"] == \"india\", \"cuisine\"] = \"indian\"\nrecipes.loc[recipes[\"cuisine\"] == \"indonesia\", \"cuisine\"] = \"indonesian\"\nrecipes.loc[recipes[\"cuisine\"] == \"iran\", \"cuisine\"] = \"iranian\"\nrecipes.loc[recipes[\"cuisine\"] == \"italy\", \"cuisine\"] = \"italian\"\nrecipes.loc[recipes[\"cuisine\"] == \"japan\", \"cuisine\"] = \"japanese\"\nrecipes.loc[recipes[\"cuisine\"] == \"israel\", \"cuisine\"] = \"jewish\"\nrecipes.loc[recipes[\"cuisine\"] == \"korea\", \"cuisine\"] = \"korean\"\nrecipes.loc[recipes[\"cuisine\"] == \"lebanon\", \"cuisine\"] = \"lebanese\"\nrecipes.loc[recipes[\"cuisine\"] == \"malaysia\", \"cuisine\"] = \"malaysian\"\nrecipes.loc[recipes[\"cuisine\"] == \"mexico\", \"cuisine\"] = \"mexican\"\nrecipes.loc[recipes[\"cuisine\"] == \"pakistan\", \"cuisine\"] = \"pakistani\"\nrecipes.loc[recipes[\"cuisine\"] == \"philippines\", \"cuisine\"] = \"philippine\"\nrecipes.loc[recipes[\"cuisine\"] == \"scandinavia\", \"cuisine\"] = \"scandinavian\"\nrecipes.loc[recipes[\"cuisine\"] == \"spain\", \"cuisine\"] = \"spanish_portuguese\"\nrecipes.loc[recipes[\"cuisine\"] == \"portugal\", \"cuisine\"] = \"spanish_portuguese\"\nrecipes.loc[recipes[\"cuisine\"] == \"switzerland\", \"cuisine\"] = \"swiss\"\nrecipes.loc[recipes[\"cuisine\"] == \"thailand\", \"cuisine\"] = \"thai\"\nrecipes.loc[recipes[\"cuisine\"] == \"turkey\", \"cuisine\"] = \"turkish\"\nrecipes.loc[recipes[\"cuisine\"] == \"vietnam\", \"cuisine\"] = \"vietnamese\"\nrecipes.loc[recipes[\"cuisine\"] == \"uk-and-ireland\", \"cuisine\"] = \"uk-and-irish\"\nrecipes.loc[recipes[\"cuisine\"] == \"irish\", \"cuisine\"] = \"uk-and-irish\"\n\n\n# remove data for cuisines with < 50 recipes:\nrecipes_counts = recipes[\"cuisine\"].value_counts()\ncuisines_indices = recipes_counts > 50\n\ncuisines_to_keep = list(np.array(recipes_counts.index.values)[np.array(cuisines_indices)])\nrecipes = recipes.loc[recipes[\"cuisine\"].isin(cuisines_to_keep)]\n\n# convert all Yes's to 1's and the No's to 0's\nrecipes = recipes.replace(to_replace=\"Yes\", value=1)\nrecipes = recipes.replace(to_replace=\"No\", value=0)",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'recipes' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# fix name of the column displaying the cuisine\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m column_names \u001b[38;5;241m=\u001b[39m \u001b[43mrecipes\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      3\u001b[0m column_names[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuisine\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m recipes\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m column_names\n",
            "\u001b[0;31mNameError\u001b[0m: name 'recipes' is not defined"
          ],
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "<hr>\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Data Modeling <a id=\"2\"></a>\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%204/images/flowchart_data_modeling.png\" width=\"500\">\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Download and install more libraries and dependencies to build decision trees.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "# import decision trees scikit-learn libraries\n%matplotlib inline\nfrom sklearn import tree\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\nimport matplotlib.pyplot as plt\n\n# If running locally, you can try using the graphviz library but we'll use sklearn's plot_tree method\n# !conda install python-graphviz --yes\n# from sklearn.tree import export_graphviz\n\nimport itertools",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Check the data again!\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "recipes.head()",
      "metadata": {
        "button": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "collapsed": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## [bamboo_tree] Only Asian and Indian Cuisines\n\nHere, we are creating a decision tree for the recipes for just some of the Asian (Korean, Japanese, Chinese, Thai) and Indian cuisines. The reason for this is because the decision tree does not run well when the data is biased towards one cuisine, in this case American cuisines. One option is to exclude the American cuisines from our analysis or just build decision trees for different subsets of the data. Let's go with the latter solution.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Let's build our decision tree using the data pertaining to the Asian and Indian cuisines and name our decision tree _bamboo_tree_.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "# select subset of cuisines\nasian_indian_recipes = recipes[recipes.cuisine.isin([\"korean\", \"japanese\", \"chinese\", \"thai\", \"indian\"])]\ncuisines = asian_indian_recipes[\"cuisine\"]\ningredients = asian_indian_recipes.iloc[:,1:]\n\nbamboo_tree = tree.DecisionTreeClassifier(max_depth=3)\nbamboo_tree.fit(ingredients, cuisines)\n\nprint(\"Decision tree model saved to bamboo_tree!\")",
      "metadata": {
        "button": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "collapsed": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Let's plot the decision tree and examine how it looks like.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "# if you're using the graphviz library, you can run these lines of code. Otherwise, this is configured to use plot_tree from sklearn\n# export_graphviz(bamboo_tree,\n#                 feature_names=list(ingredients.columns.values),\n#                 out_file=\"bamboo_tree.dot\",\n#                 class_names=np.unique(cuisines),\n#                 filled=True,\n#                 node_ids=True,\n#                 special_characters=True,\n#                 impurity=False,\n#                 label=\"all\",\n#                 leaves_parallel=False)\n\n# with open(\"bamboo_tree.dot\") as bamboo_tree_image:\n#     bamboo_tree_graph = bamboo_tree_image.read()\n# graphviz.Source(bamboo_tree_graph)\n\nplt.figure(figsize=(40,20))  # customize according to the size of your tree\n_ = tree.plot_tree(bamboo_tree,\n                   feature_names = list(ingredients.columns.values),\n                   class_names=np.unique(cuisines),filled=True,\n                   node_ids=True,\n                   impurity=False,\n                   label=\"all\",\n                   fontsize=20, rounded = True)\nplt.show()",
      "metadata": {
        "button": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "collapsed": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "The decision tree learned:\n\n-   If a recipe contains _cumin_ and _fish_ and **no** _yoghurt_, then it is most likely a **Thai** recipe.\n-   If a recipe contains _cumin_ but **no** _fish_ and **no** _soy_sauce_, then it is most likely an **Indian** recipe.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "You can analyze the remaining branches of the tree to come up with similar rules for determining the cuisine of different recipes. \n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Feel free to select another subset of cuisines and build a decision tree of their recipes. You can select some European cuisines and build a decision tree to explore the ingredients that differentiate them.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Model Evaluation <a id=\"4\"></a>\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%204/images/flowchart_evaluation.png\" width=\"500\">\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "To evaluate our model of Asian and Indian cuisines, we will split our dataset into a training set and a test set. We will build the decision tree using the training set. Then, we will test the model on the test set and compare the cuisines that the model predicts to the actual cuisines. \n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Let's first create a new dataframe using only the data pertaining to the Asian and the Indian cuisines, and let's call the new dataframe **bamboo**.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "bamboo = recipes[recipes.cuisine.isin([\"korean\", \"japanese\", \"chinese\", \"thai\", \"indian\"])]",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Let's see how many recipes exist for each cuisine.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "bamboo[\"cuisine\"].value_counts()",
      "metadata": {
        "button": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "collapsed": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Let's remove 30 recipes from each cuisine to use as the test set, and let's name this test set **bamboo_test**.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "# set sample size\nsample_n = 30",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Create a dataframe containing 30 recipes from each cuisine, selected randomly.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "# take 30 recipes from each cuisine\nrandom.seed(1234) # set random seed\nbamboo_test = bamboo.groupby(\"cuisine\", group_keys=False).apply(lambda x: x.sample(sample_n))\n\nbamboo_test_ingredients = bamboo_test.iloc[:,1:] # ingredients\nbamboo_test_cuisines = bamboo_test[\"cuisine\"] # corresponding cuisines or labels",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Check that there are 30 recipes for each cuisine.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "# check that we have 30 recipes from each cuisine\nbamboo_test[\"cuisine\"].value_counts()",
      "metadata": {
        "button": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "collapsed": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Next, let's create the training set by removing the test set from the **bamboo** dataset, and let's call the training set **bamboo_train**.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "bamboo_test_index = bamboo.index.isin(bamboo_test.index)\nbamboo_train = bamboo[~bamboo_test_index]\n\nbamboo_train_ingredients = bamboo_train.iloc[:,1:] # ingredients\nbamboo_train_cuisines = bamboo_train[\"cuisine\"] # corresponding cuisines or labels",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Check that there are 30 _fewer_ recipes now for each cuisine.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "bamboo_train[\"cuisine\"].value_counts()",
      "metadata": {
        "button": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "collapsed": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Let's build the decision tree using the training set, **bamboo_train**, and name the generated tree **bamboo_train_tree** for prediction.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "bamboo_train_tree = tree.DecisionTreeClassifier(max_depth=15)\nbamboo_train_tree.fit(bamboo_train_ingredients, bamboo_train_cuisines)\n\nprint(\"Decision tree model saved to bamboo_train_tree!\")",
      "metadata": {
        "button": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "collapsed": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Let's plot the decision tree and explore it.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "# export_graphviz(bamboo_train_tree,\n#                 feature_names=list(bamboo_train_ingredients.columns.values),\n#                 out_file=\"bamboo_train_tree.dot\",\n#                 class_names=np.unique(bamboo_train_cuisines),\n#                 filled=True,\n#                 node_ids=True,\n#                 special_characters=True,\n#                 impurity=False,\n#                 label=\"all\",\n#                 leaves_parallel=False)\n\n# with open(\"bamboo_train_tree.dot\") as bamboo_train_tree_image:\n#     bamboo_train_tree_graph = bamboo_train_tree_image.read()\n# graphviz.Source(bamboo_train_tree_graph)\n\nplt.figure(figsize=(40,20))  # customize according to the size of your tree\n_ = tree.plot_tree(bamboo_train_tree,\n                   feature_names=list(bamboo_train_ingredients.columns.values),\n                   class_names=np.unique(bamboo_train_cuisines),\n                   filled=True,\n                   node_ids=True,\n                   impurity=False,\n                   label=\"all\",\n                   fontsize=10, rounded = True)\nplt.show()",
      "metadata": {
        "button": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "collapsed": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Now that we defined our tree to be deeper, more decision nodes are generated.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "#### Now let's test our model on the test data.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "bamboo_pred_cuisines = bamboo_train_tree.predict(bamboo_test_ingredients)",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "To quantify how well the decision tree is able to determine the cuisine of each recipe correctly, we will create a confusion matrix which presents a nice summary on how many recipes from each cuisine are correctly classified. It also sheds some light on what cuisines are being confused with what other cuisines.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "So let's go ahead and create the confusion matrix for how well the decision tree is able to correctly classify the recipes in **bamboo_test**.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "test_cuisines = np.unique(bamboo_test_cuisines)\nbamboo_confusion_matrix = confusion_matrix(bamboo_test_cuisines, bamboo_pred_cuisines, labels = test_cuisines)\ntitle = 'Bamboo Confusion Matrix'\ncmap = plt.cm.Blues\n\nplt.figure(figsize=(8, 6))\nbamboo_confusion_matrix = (\n    bamboo_confusion_matrix.astype('float') / bamboo_confusion_matrix.sum(axis=1)[:, np.newaxis]\n    ) * 100\n\nplt.imshow(bamboo_confusion_matrix, interpolation='nearest', cmap=cmap)\nplt.title(title)\nplt.colorbar()\ntick_marks = np.arange(len(test_cuisines))\nplt.xticks(tick_marks, test_cuisines)\nplt.yticks(tick_marks, test_cuisines)\n\nfmt = '.2f'\nthresh = bamboo_confusion_matrix.max() / 2.\nfor i, j in itertools.product(range(bamboo_confusion_matrix.shape[0]), range(bamboo_confusion_matrix.shape[1])):\n    plt.text(j, i, format(bamboo_confusion_matrix[i, j], fmt),\n             horizontalalignment=\"center\",\n             color=\"white\" if bamboo_confusion_matrix[i, j] > thresh else \"black\")\n\nplt.tight_layout()\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\n\nplt.show()",
      "metadata": {
        "button": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "collapsed": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "After running the above code, you should get a confusion matrix similar to the following:\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%204/images/lab4_fig6_confusion_matrix.png\" width=\"500\">\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "The rows represent the actual cuisines from the dataset and the columns represent the predicted ones. Each row should sum to 100%. According to this confusion matrix, we make the following observations:\n\n-   Using the first row in the confusion matrix, 60% of the **Chinese** recipes in **bamboo_test** were correctly classified by our decision tree whereas 37% of the **Chinese** recipes were misclassified as **Korean** and 3% were misclassified as **Indian**.\n\n-   Using the Indian row, 77% of the **Indian** recipes in **bamboo_test** were correctly classified by our decision tree and 3% of the **Indian** recipes were misclassified as **Chinese** and 13% were misclassified as **Korean** and 7% were misclassified as **Thai**.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Please note** that because decision trees are created using random sampling of the datapoints in the training set, then you may not get the same results every time you create the decision tree even using the same training set. The performance should still be comparable though! So don't worry if you get slightly different numbers in your confusion matrix than the ones shown above.\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Using the reference confusion matrix, how many **Japanese** recipes were correctly classified by our decision tree?\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "raw",
      "source": "Your Answer:\n\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for a solution</summary>\n\n```python\n    #The correct answer is:\n    36.67%.\n```\n\n</details>\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Also using the reference confusion matrix, how many **Korean** recipes were misclassified as **Japanese**?\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "raw",
      "source": "Your Answer:\n\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for a solution</summary>\n\n```python\n    #The correct answer is:\n     3.33%.\n```\n\n</details>\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "What cuisine has the least number of recipes correctly classified by the decision tree using the reference confusion matrix?\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "raw",
      "source": "Your Answer:\n\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for a solution</summary>\n\n```python\n    #The correct answer is:\n     Japanese cuisine, with 36.67% only.\n```\n\n</details>\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "<br>\n<hr>\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Thank you for completing this lab!\n\nThis notebook is part of a course called _The Data Science Method_. If you accessed this notebook outside the course, you can take this course, online by clicking [here](https://cocl.us/DS0103EN-Exercise-From-Modeling-to-Evaluation).\n\n## Author\n\n<a href=\"https://www.linkedin.com/in/aklson/\" target=\"_blank\">Alex Aklson</a>\n\n## Change Log\n\n| Date (YYYY-MM-DD) | Version | Changed By | Change Description                 |\n| ----------------- | ------- | ---------- | ---------------------------------- |\n| 2021-04-06        | 2.2     | Malika     | Updated Dataset link               |\n| 2020-09-25        | 2.1     | Lakshmi    | Fixed Typo errors                  |\n| 2020-08-27        | 2.0     | Lavanya    | Moved lab to course repo in GitLab |\n\n<hr>\n\n## <h3 align=\"center\">  IBM Corporation 2020. All rights reserved. <h3/>\n",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      }
    }
  ]
}